{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "데이터 전처리"
      ],
      "metadata": {
        "id": "VWjBoaqS_3h2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "data_folder = '/content/drive/MyDrive/1month_data'\n",
        "all_files = os.listdir(data_folder)\n",
        "csv_files = [os.path.join(data_folder, f) for f in all_files if f.endswith('.csv')]\n",
        "\n",
        "def read_csv_file(file_path):\n",
        "    encodings = ['utf-8', 'cp949', 'euc-kr']  # List of possible encodings\n",
        "    for encoding in encodings:\n",
        "        try:\n",
        "            return pd.read_csv(file_path, encoding=encoding)\n",
        "        except (UnicodeDecodeError, pd.errors.EmptyDataError, pd.errors.ParserError):\n",
        "            continue\n",
        "    raise ValueError(f\"Could not read file {file_path} with any encoding.\")\n",
        "\n",
        "valid_dataframes = []\n",
        "for file in csv_files:\n",
        "    try:\n",
        "        df = read_csv_file(file)\n",
        "        if not df.empty:\n",
        "          valid_dataframes.append(df)\n",
        "    except ValueError as e:\n",
        "        print(e)\n",
        "\n",
        "if valid_dataframes:\n",
        "    combined_data = pd.concat(valid_dataframes, ignore_index=True)\n",
        "else:\n",
        "    combined_data = pd.DataFrame()\n",
        "\n",
        "combined_data = combined_data.drop(columns=[\n",
        "    \"생성일\",\n",
        "    \"소비전류\",\n",
        "    \"진동센서1\",\n",
        "    \"진동센서2\",\n",
        "    \"운전시간\",\n",
        "    \"정상 운전 확률\",\n",
        "    \"송풍기 고장 확률\",\n",
        "    \"AIR 댐퍼 고장 확률\",\n",
        "    \"GAS 앰퍼 고장 확률\",\n",
        "    \"확률 업데이트 시간\",\n",
        "    \"순간 스팀량\",\n",
        "    \"입출력법 효율\",\n",
        "    \"열 손실법 효율\",\n",
        "    \"효율(입출력법-스팀)\",\n",
        "    \"배기 재 순환 온도\",\n",
        "    \"버너온도\"\n",
        "])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "numeric_columns = combined_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "combined_data[numeric_columns] = scaler.fit_transform(combined_data[numeric_columns])\n",
        "\n",
        "# Select numerical columns only\n",
        "numerical_columns = combined_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Fill missing values in numerical columns with the mean value\n",
        "combined_data[numerical_columns] = combined_data[numerical_columns].apply(lambda col: col.fillna(col.mean()))\n",
        "\n",
        "# For categorical columns, fill missing values with the most frequent value\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "combined_data[combined_data.select_dtypes(include=['object']).columns] = cat_imputer.fit_transform(combined_data.select_dtypes(include=['object']))\n",
        "\n",
        "# Encode categorical variables (if any)\n",
        "label_encoder = LabelEncoder()\n",
        "for column in combined_data.select_dtypes(include=['object']).columns:\n",
        "    combined_data[column] = label_encoder.fit_transform(combined_data[column])\n",
        "\n",
        "combined_data.to_csv('/content/drive/MyDrive/preprocessed_boiler_data.csv', index=False, encoding='utf-8')\n",
        "combined_data.head()\n",
        "\n",
        "#checking if data preprocessing was correct\n",
        "print(combined_data.isna().sum())  # Shows the count of NaNs in each column\n",
        "print(combined_data.isna().sum().sum())  # Total count of missing values\n",
        "print(combined_data.info())"
      ],
      "metadata": {
        "id": "WEZZ8KHVSeQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c177602-bd5d-483f-b518-e6f0cab11248"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "부하율             0\n",
            "설정 압력           0\n",
            "보일러 압력          0\n",
            "송풍기 인버터 출력      0\n",
            "송풍기 입력          0\n",
            "급수 펌프           0\n",
            "급수펌프 입력         0\n",
            "가스 댐퍼           0\n",
            "가스 댐퍼 입력        0\n",
            "Air 댐퍼          0\n",
            "Air 댐퍼 입력       0\n",
            "재순환 댐퍼          0\n",
            "재순환 외기 댐퍼       0\n",
            "재순환 댐퍼 입력       0\n",
            "재순환 외기 댐퍼 입력    0\n",
            "급수 수위           0\n",
            "보일러 온도          0\n",
            "배기가스온도1         0\n",
            "배기가스온도2         0\n",
            "배기가스온도3         0\n",
            "에코 온도1          0\n",
            "에코 온도2          0\n",
            "배기가스 NOx        0\n",
            "배기가스 O2         0\n",
            "재순환 O2          0\n",
            "재순환 NOx         0\n",
            "급수량(적산유량)       0\n",
            "급수량(순간유량)       0\n",
            "연료량(적산유량)       0\n",
            "연료량(순간유량)       0\n",
            "효율(순간)          0\n",
            "dtype: int64\n",
            "0\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1884101 entries, 0 to 1884100\n",
            "Data columns (total 31 columns):\n",
            " #   Column        Dtype  \n",
            "---  ------        -----  \n",
            " 0   부하율           float64\n",
            " 1   설정 압력         float64\n",
            " 2   보일러 압력        float64\n",
            " 3   송풍기 인버터 출력    float64\n",
            " 4   송풍기 입력        float64\n",
            " 5   급수 펌프         float64\n",
            " 6   급수펌프 입력       float64\n",
            " 7   가스 댐퍼         float64\n",
            " 8   가스 댐퍼 입력      float64\n",
            " 9   Air 댐퍼        float64\n",
            " 10  Air 댐퍼 입력     float64\n",
            " 11  재순환 댐퍼        float64\n",
            " 12  재순환 외기 댐퍼     float64\n",
            " 13  재순환 댐퍼 입력     float64\n",
            " 14  재순환 외기 댐퍼 입력  float64\n",
            " 15  급수 수위         float64\n",
            " 16  보일러 온도        float64\n",
            " 17  배기가스온도1       float64\n",
            " 18  배기가스온도2       float64\n",
            " 19  배기가스온도3       int64  \n",
            " 20  에코 온도1        float64\n",
            " 21  에코 온도2        int64  \n",
            " 22  배기가스 NOx      float64\n",
            " 23  배기가스 O2       float64\n",
            " 24  재순환 O2        float64\n",
            " 25  재순환 NOx       float64\n",
            " 26  급수량(적산유량)     float64\n",
            " 27  급수량(순간유량)     float64\n",
            " 28  연료량(적산유량)     float64\n",
            " 29  연료량(순간유량)     float64\n",
            " 30  효율(순간)        float64\n",
            "dtypes: float64(29), int64(2)\n",
            "memory usage: 445.6 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. 필요한 라이브러리 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from scipy.stats import randint\n",
        "\n",
        "# 2. 전처리된 데이터 사용 (전처리 코드는 이미 실행된 상태라고 가정)\n",
        "# df = 전처리된 데이터프레임\n",
        "\n",
        "# 3. 독립 변수(X)와 종속 변수(y) 설정\n",
        "# 전처리한 데이터에서 종속 변수에 해당하는 열을 선택합니다.\n",
        "X = combined_data.drop(columns=['효율(순간)'])  # 종속 변수 제외\n",
        "y = combined_data['효율(순간)']\n",
        "\n",
        "# 4. 데이터 분할: 훈련 데이터와 테스트 데이터로 분할\n",
        "# 여기에서 train_test_split을 사용하여 X_train, X_test, y_train, y_test를 생성합니다.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 예시: 80% 훈련, 20% 테스트\n",
        "\n",
        "# 5. Random Forest Model with RandomizedSearchCV for hyperparameter tuning\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_distributions = {\n",
        "    'n_estimators': [50, 100, 200],      # Number of trees\n",
        "    'max_depth': [None, 10, 15, 20, 25],           # Maximum depth of the tree\n",
        "    'min_samples_split': [2,5,10],   # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1,2,4],    # Minimum number of samples required to be at a leaf node\n",
        "    'max_features':['sqrt', 'log2'],  # Number of features to consider at each split\n",
        "    'min_weight_fraction_leaf': [0.0, 0.1, 0.2]  # 리프 노드의 가중치 샘플 최소값\n",
        "}\n",
        "\n",
        "# Randomized Search CV with 5-fold cross-validation\n",
        "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_distributions,\n",
        "                                   n_iter=50, cv=5, verbose=2, n_jobs=-1, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best hyperparameters found by RandomizedSearchCV:\")\n",
        "print(random_search.best_params_)\n",
        "\n",
        "# 6. Model evaluation using test data\n",
        "\n",
        "y_pred = random_search.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "mae = np.mean(np.abs(y_test - y_pred))\n",
        "rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))\n",
        "mse = np.mean((y_test - y_pred) ** 2)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(f\"MAPE: {mape:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJEbWHBzo6uI",
        "outputId": "3da0386e-476d-4e36-bdbb-49b9506d789d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters found by RandomizedSearchCV:\n",
            "{'n_estimators': 50, 'min_weight_fraction_leaf': 0.0, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 25}\n",
            "MAPE: 7.5247\n",
            "MAE: 0.0190\n",
            "RMSE: 0.0463\n",
            "MSE: 0.0021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gmCxi7IkSNJq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}